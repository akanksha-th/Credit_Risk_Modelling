{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import chi2_contingency\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_recall_fscore_support\n",
    "import warnings\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = pd.read_excel(\"C:/Users/Akanksha/Credit_Risk_Modelling/data/case_study1.xlsx\")\n",
    "a2 = pd.read_excel(\"C:/Users/Akanksha/Credit_Risk_Modelling/data/case_study2.xlsx\")\n",
    "\n",
    "\n",
    "df1 = a1.copy()\n",
    "df2 = a2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.loc[df1['Age_Oldest_TL'] != -99999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_be_removed = []\n",
    "\n",
    "for i in df2.columns:\n",
    "    if df2.loc[df2[i] == -99999].shape[0] > 10000:\n",
    "        columns_to_be_removed .append(i)\n",
    "\n",
    "\n",
    "\n",
    "df2 = df2.drop(columns_to_be_removed, axis =1)\n",
    "\n",
    "\n",
    "\n",
    "for i in df2.columns:\n",
    "    df2 = df2.loc[ df2[i] != -99999 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking common column names\n",
    "for i in list(df1.columns):\n",
    "    if i in list(df2.columns):\n",
    "        print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two dataframes, inner join so that no nulls are present\n",
    "df = pd. merge ( df1, df2, how ='inner', left_on = ['PROSPECTID'], right_on = ['PROSPECTID'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how many columns are categorical\n",
    "for i in df.columns:\n",
    "    if df[i].dtype == 'object':\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi-square test\n",
    "for i in ['MARITALSTATUS', 'EDUCATION', 'GENDER', 'last_prod_enq2', 'first_prod_enq2']:\n",
    "    chi2, pval, _, _ = chi2_contingency(pd.crosstab(df[i], df['Approved_Flag']))\n",
    "    print(i, '---', pval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VIF for numerical columns\n",
    "numeric_columns = []\n",
    "for i in df.columns:\n",
    "    if df[i].dtype != 'object' and i not in ['PROSPECTID','Approved_Flag']:\n",
    "        numeric_columns.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VIF sequentially check\n",
    "\n",
    "vif_data = df[numeric_columns]\n",
    "total_columns = vif_data.shape[1]\n",
    "columns_to_be_kept = []\n",
    "column_index = 0\n",
    "\n",
    "\n",
    "\n",
    "for i in range (0,total_columns):\n",
    "    \n",
    "    vif_value = variance_inflation_factor(vif_data, column_index)\n",
    "    print (column_index,'---',vif_value)\n",
    "    \n",
    "    \n",
    "    if vif_value <= 6:\n",
    "        columns_to_be_kept.append( numeric_columns[i] )\n",
    "        column_index = column_index+1\n",
    "    \n",
    "    else:\n",
    "        vif_data = vif_data.drop([ numeric_columns[i] ] , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f_oneway\n",
    "\n",
    "columns_to_be_kept_numerical = []\n",
    "\n",
    "for i in columns_to_be_kept:\n",
    "    a = list(df[i])  \n",
    "    b = list(df['Approved_Flag'])  \n",
    "    \n",
    "    group_P1 = [value for value, group in zip(a, b) if group == 'P1']\n",
    "    group_P2 = [value for value, group in zip(a, b) if group == 'P2']\n",
    "    group_P3 = [value for value, group in zip(a, b) if group == 'P3']\n",
    "    group_P4 = [value for value, group in zip(a, b) if group == 'P4']\n",
    "\n",
    "\n",
    "    f_statistic, p_value = f_oneway(group_P1, group_P2, group_P3, group_P4)\n",
    "\n",
    "    if p_value <= 0.05:\n",
    "        columns_to_be_kept_numerical.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# listing all the final features\n",
    "features = columns_to_be_kept_numerical + ['MARITALSTATUS', 'EDUCATION', 'GENDER', 'last_prod_enq2', 'first_prod_enq2']\n",
    "df = df[features + ['Approved_Flag']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MARITALSTATUS'].unique()    \n",
    "df['EDUCATION'].unique()\n",
    "df['GENDER'].unique()\n",
    "df['last_prod_enq2'].unique()\n",
    "df['first_prod_enq2'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['EDUCATION'] == 'SSC',['EDUCATION']]              = 1\n",
    "df.loc[df['EDUCATION'] == '12TH',['EDUCATION']]             = 2\n",
    "df.loc[df['EDUCATION'] == 'GRADUATE',['EDUCATION']]         = 3\n",
    "df.loc[df['EDUCATION'] == 'UNDER GRADUATE',['EDUCATION']]   = 3\n",
    "df.loc[df['EDUCATION'] == 'POST-GRADUATE',['EDUCATION']]    = 4\n",
    "df.loc[df['EDUCATION'] == 'OTHERS',['EDUCATION']]           = 1\n",
    "df.loc[df['EDUCATION'] == 'PROFESSIONAL',['EDUCATION']]     = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['EDUCATION'].value_counts()\n",
    "df['EDUCATION'] = df['EDUCATION'].astype(int)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = pd.get_dummies(df, columns=['MARITALSTATUS','GENDER', 'last_prod_enq2' ,'first_prod_enq2'])\n",
    "\n",
    "df_encoded.info()\n",
    "k = df_encoded.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Random Forest\n",
    "\n",
    "y = df_encoded['Approved_Flag']\n",
    "x = df_encoded. drop ( ['Approved_Flag'], axis = 1 )\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators = 200, random_state=42)\n",
    "\n",
    "\n",
    "rf_classifier.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = rf_classifier.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print ()\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print ()\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred)\n",
    "\n",
    "\n",
    "for i, v in enumerate(['p1', 'p2', 'p3', 'p4']):\n",
    "    print(f\"Class {v}:\")\n",
    "    print(f\"Precision: {precision[i]}\")\n",
    "    print(f\"Recall: {recall[i]}\")\n",
    "    print(f\"F1 Score: {f1_score[i]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. xgboost\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "xgb_classifier = xgb.XGBClassifier(objective='multi:softmax',  num_class=4)\n",
    "\n",
    "\n",
    "y = df_encoded['Approved_Flag']\n",
    "x = df_encoded. drop ( ['Approved_Flag'], axis = 1 )\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "xgb_classifier.fit(x_train, y_train)\n",
    "y_pred = xgb_classifier.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print ()\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print ()\n",
    "\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred)\n",
    "\n",
    "for i, v in enumerate(['p1', 'p2', 'p3', 'p4']):\n",
    "    print(f\"Class {v}:\")\n",
    "    print(f\"Precision: {precision[i]}\")\n",
    "    print(f\"Recall: {recall[i]}\")\n",
    "    print(f\"F1 Score: {f1_score[i]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "y = df_encoded['Approved_Flag']\n",
    "x = df_encoded. drop ( ['Approved_Flag'], axis = 1 )\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "dt_model = DecisionTreeClassifier(max_depth=20, min_samples_split=10)\n",
    "dt_model.fit(x_train, y_train)\n",
    "y_pred = dt_model.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print ()\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print ()\n",
    "\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred)\n",
    "\n",
    "for i, v in enumerate(['p1', 'p2', 'p3', 'p4']):\n",
    "    print(f\"Class {v}:\")\n",
    "    print(f\"Precision: {precision[i]}\")\n",
    "    print(f\"Recall: {recall[i]}\")\n",
    "    print(f\"F1 Score: {f1_score[i]}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
